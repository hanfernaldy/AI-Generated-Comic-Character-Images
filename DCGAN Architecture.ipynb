{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Architecture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(keras.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss'))\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric]\n",
    "\n",
    "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_real = self.discriminator(real_images, training=True)\n",
    "            real_labels = tf.ones((batch_size, 1))\n",
    "            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels))\n",
    "            d_loss_real = self.loss_fn(real_labels, pred_real)\n",
    "\n",
    "            fake_images = self.generator(random_noise)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
    "\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "\n",
    "        gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n",
    "\n",
    "        labels = tf.ones((batch_size, 1))\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_noise, training=True)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            g_loss = self.loss_fn(labels, pred_fake)\n",
    "\n",
    "        gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n",
    "\n",
    "        # Calculate metrics\n",
    "        self.accuracy_metric.update_state(tf.concat([tf.ones_like(pred_real), tf.zeros_like(pred_fake)], axis=0),\n",
    "                                          tf.concat([tf.math.sigmoid(pred_real), tf.math.sigmoid(pred_fake)], axis=0))\n",
    "        self.precision_metric.update_state(tf.concat([tf.ones_like(pred_real), tf.zeros_like(pred_fake)], axis=0),\n",
    "                                            tf.concat([tf.math.sigmoid(pred_real), tf.math.sigmoid(pred_fake)], axis=0))\n",
    "        self.recall_metric.update_state(tf.concat([tf.ones_like(pred_real), tf.zeros_like(pred_fake)], axis=0),\n",
    "                                         tf.concat([tf.math.sigmoid(pred_real), tf.math.sigmoid(pred_fake)], axis=0))\n",
    "\n",
    "        # Update loss metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {'d_loss': self.d_loss_metric.result(), 'g_loss': self.g_loss_metric.result()\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_imgs=25, latent_dim=100):\n",
    "        self.num_imgs = num_imgs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.noise = tf.random.normal([25, latent_dim])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        g_img = self.model.generator(self.noise)\n",
    "        g_img = (g_img * 127.5) + 127.5\n",
    "        g_img.numpy()\n",
    "        \n",
    "        fig = plt.figure(figsize=(5, 5))\n",
    "        for i in range(self.num_imgs):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            img = array_to_img(g_img[i])\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.generator.save('generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
